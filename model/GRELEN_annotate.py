import torch.nn as nn  # å¯¼å…¥ PyTorch çš„ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œæä¾›äº†æ„å»ºç¥ç»ç½‘ç»œæ‰€éœ€çš„åŠŸèƒ½
import sys  # å¯¼å…¥ç³»ç»Ÿæ¨¡å—ï¼Œç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
sys.path.append('..')  # å°†ä¸Šçº§ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
from lib.utils import *  # ä» lib.utils æ¨¡å—ä¸­å¯¼å…¥æ‰€æœ‰åŠŸèƒ½ï¼Œç”¨äºåç»­ä»£ç ä¸­çš„å·¥å…·å‡½æ•°

# å®šä¹‰ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹ï¼ˆMLPï¼‰
"""
å¤šå±‚æ„ŸçŸ¥æœº(MLP,Multilayer Perceptron)ä¹Ÿå«äººå·¥ç¥ç»ç½‘ç»œ(ANN,Artificial Neural Network)
Figure3ä¸­çš„Feature Extraction(æå–ç‰¹å¾)
***è¾“å…¥æ—¶é—´åºåˆ—æ•°æ®é€šè¿‡MLPç±»è¿›è¡Œç‰¹å¾æå–***
å¤šä¸ªæ—¶é—´åºåˆ—Sé€šè¿‡ç‰¹å¾æå–è½¬æ¢ä¸ºéšå«è¡¨ç¤ºh

ç›¸å…³ä»£ç ï¼š
X = self.mlp1(inputs)  # ä½¿ç”¨ MLP æå–ç‰¹å¾Graph_learnerç±»ä¸­çš„forwardå‡½æ•°
"""
class MLP(nn.Module):
    """Two-layer fully-connected ELU net with batch norm."""
    # å®šä¹‰ä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚ã€ELU(æŒ‡æ•°çº¿æ€§å•å…ƒ) æ¿€æ´»å‡½æ•°å’Œæ‰¹é‡å½’ä¸€åŒ–çš„å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹

    def __init__(self, n_in, n_hid, n_out, do_prob=0.):
        """
        åˆå§‹åŒ– MLP æ¨¡å‹
        :param n_in: è¾“å…¥å±‚çš„èŠ‚ç‚¹æ•°
        :param n_hid: éšè—å±‚çš„èŠ‚ç‚¹æ•°
        :param n_out: è¾“å‡ºå±‚çš„èŠ‚ç‚¹æ•°
        :param do_prob: dropout çš„æ¦‚ç‡ï¼Œé»˜è®¤å€¼ä¸º 0(å³ä¸ä½¿ç”¨ dropout)
        """
        super(MLP, self).__init__()  # è°ƒç”¨çˆ¶ç±»ï¼ˆnn.Moduleï¼‰çš„åˆå§‹åŒ–å‡½æ•°
        self.fc1 = nn.Linear(n_in, n_hid)  # å®šä¹‰ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ç»´åº¦ä¸º n_inï¼Œè¾“å‡ºç»´åº¦ä¸º n_hid
        self.fc2 = nn.Linear(n_hid, n_out)  # å®šä¹‰ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ç»´åº¦ä¸º n_hidï¼Œè¾“å‡ºç»´åº¦ä¸º n_out
        self.bn = nn.BatchNorm1d(n_out)  # å®šä¹‰æ‰¹é‡å½’ä¸€åŒ–å±‚ï¼Œç”¨äºè§„èŒƒåŒ–è¾“å‡ºå±‚çš„è¾“å‡º
        self.dropout_prob = do_prob  # ä¿å­˜ dropout æ¦‚ç‡
        # dropout æ˜¯ä¸€ç§é˜²æ­¢ç¥ç»ç½‘ç»œè¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–æŠ€æœ¯ã€‚åŸºæœ¬æ€æƒ³ï¼šåœ¨æ¯æ¬¡è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œè¿«ä½¿ç¥ç»ç½‘ç»œä¸ä¾èµ–æŸäº›ç‰¹å®šçš„èŠ‚ç‚¹å’Œè·¯å¾„ï¼Œå¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›

        self.init_weights()  # è°ƒç”¨åˆå§‹åŒ–æƒé‡çš„æ–¹æ³•

    def init_weights(self):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¸­æ‰€æœ‰å…¨è¿æ¥å±‚å’Œæ‰¹é‡å½’ä¸€åŒ–å±‚çš„æƒé‡å’Œåç½®
        """
        for m in self.modules():  # éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å­æ¨¡å—
            if isinstance(m, nn.Linear):  # å¦‚æœå­æ¨¡å—æ˜¯å…¨è¿æ¥å±‚
                nn.init.xavier_normal_(m.weight.data)  # ä½¿ç”¨ Xavier æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
                m.bias.data.fill_(0.1)  # å°†åç½®åˆå§‹åŒ–ä¸º 0.1
            elif isinstance(m, nn.BatchNorm1d):  # å¦‚æœå­æ¨¡å—æ˜¯æ‰¹é‡å½’ä¸€åŒ–å±‚
                m.weight.data.fill_(1)  # å°†æƒé‡åˆå§‹åŒ–ä¸º 1
                m.bias.data.zero_()  # å°†åç½®åˆå§‹åŒ–ä¸º 0

    def batch_norm(self, inputs):
        """
        æ‰¹é‡å½’ä¸€åŒ–
        :param inputs: è¾“å…¥æ•°æ®
        :return: æ‰¹é‡å½’ä¸€åŒ–åçš„æ•°æ®
        """
        x = inputs.view(inputs.size(0) * inputs.size(1), -1)  # å°†è¾“å…¥æ•°æ®é‡å¡‘ä¸ºäºŒç»´å½¢å¼
        x = self.bn(x)  # åº”ç”¨æ‰¹é‡å½’ä¸€åŒ–
        return x.view(inputs.size(0), inputs.size(1), -1)  # å°†æ•°æ®é‡å¡‘å›åŸå§‹çš„ä¸‰ç»´å½¢å¼

    def forward(self, inputs):
        """
        å‰å‘ä¼ æ’­
        :param inputs: è¾“å…¥æ•°æ®
        :return: æ¨¡å‹çš„è¾“å‡º
        """
        x = F.elu(self.fc1(inputs))  # é€šè¿‡ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå¹¶ä½¿ç”¨ ELU æ¿€æ´»å‡½æ•°
        x = F.dropout(x, self.dropout_prob, training=self.training)  # åº”ç”¨ dropout
        x = F.elu(self.fc2(x))  # é€šè¿‡ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼Œå¹¶ä½¿ç”¨ ELU æ¿€æ´»å‡½æ•°
        return self.batch_norm(x)  # è¿”å›æ‰¹é‡å½’ä¸€åŒ–åçš„è¾“å‡º

# å®šä¹‰ä¸€ä¸ªå›¾å­¦ä¹ æ¨¡å‹
"""
Figure3ä¸­çš„Relation Inference(å…³ç³»æ¨æ–­)éƒ¨åˆ†,æ˜¾ç¤ºäº†å¦‚ä½•ä»æå–çš„ç‰¹å¾hæ¨æ–­å‡ºèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ğœƒ

åœ¨è¾“å…¥æ•°æ®ä¸­å­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»
1.ç‰¹å¾æå–:é€šè¿‡MLPæ¨¡å‹å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç‰¹å¾æå–,å°†å…¶è½¬æ¢ä¸ºæ›´é«˜ç»´çš„éšå«è¡¨ç¤ºã€‚   ä»£ç ä¸­çš„ self.mlp1 éƒ¨åˆ†
2.è®¡ç®—æŸ¥è¯¢å’Œé”®:é€šè¿‡'wq'å’Œ'wk'çº¿æ€§å±‚è®¡ç®—æŸ¥è¯¢å’Œé”®å‘é‡ã€‚   ä»£ç ä¸­çš„ self.Wq(X) å’Œ self.Wk(X) éƒ¨åˆ†ã€‚
3.å…³ç³»æ¨æ–­:é€šè¿‡æŸ¥è¯¢å‘é‡å’Œé”®å‘é‡çš„ç‚¹ç§¯è®¡ç®—æ³¨æ„åŠ›æƒé‡çŸ©é˜µã€‚é€šè¿‡å‘é‡ä¹‹é—´çš„ç‚¹ç§¯æ¥æ¨æ–­èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚ç‚¹ç§¯ç»“æœè¡¨ç¤ºèŠ‚ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦å’Œå…³è”ç¨‹åº¦,å³æ³¨æ„åŠ›æƒé‡ã€‚
ä»£ç ä¸­çš„ torch.matmul(Xq, Xk.transpose(-1, -2)) éƒ¨åˆ†ï¼Œå¯¹åº”å›¾ä¸­çš„å…³ç³»æ¨æ–­éƒ¨åˆ†ã€‚
"""
class Graph_learner(nn.Module):
    def __init__(self, n_in, n_hid, n_head_dim, head, do_prob=0.):  # n_in = T
        """
        åˆå§‹åŒ–å›¾å­¦ä¹ æ¨¡å‹
        :param n_in: è¾“å…¥ç»´åº¦ï¼ˆç‰¹å¾æ•°é‡ T)
        :param n_hid: éšè—å±‚ç»´åº¦ï¼ˆç”¨äº MLP çš„éšè—å±‚å¤§å°ï¼‰
        :param n_head_dim: æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
        :param head: æ³¨æ„åŠ›å¤´çš„æ•°é‡
        :param do_prob: dropout çš„æ¦‚ç‡ï¼ˆé»˜è®¤å€¼ä¸º 0)
        """
        super(Graph_learner, self).__init__()
        self.n_hid = n_hid  # éšè—å±‚çš„ç»´åº¦
        self.head = head  # å¤´çš„æ•°é‡
        self.n_in = n_in  # è¾“å…¥ç»´åº¦
        self.n_head_dim = n_head_dim  # æ¯ä¸ªå¤´çš„ç»´åº¦

        # å®šä¹‰ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç”¨äºç‰¹å¾æå–
        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)  # å®šä¹‰ä¸€ä¸ª MLP æ¨¡å‹ï¼Œç”¨äºå¤„ç†è¾“å…¥æ•°æ®
        
        # Wq å’Œ Wk æ˜¯ç”¨äºè®¡ç®—æŸ¥è¯¢ï¼ˆQueryï¼‰å’Œé”®ï¼ˆKeyï¼‰çš„çº¿æ€§å˜æ¢å±‚
        # è¾“å‡ºç»´åº¦ n_head_dim * headï¼Œå³å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­æ¯ä¸ªå¤´çš„ç»´åº¦ä¹˜ä»¥å¤´çš„æ•°é‡
        self.Wq = nn.Linear(n_hid, n_head_dim * head)  # å®šä¹‰æŸ¥è¯¢æƒé‡çŸ©é˜µï¼Œç»´åº¦ä¸º n_hid åˆ° n_head_dim * head
        self.Wk = nn.Linear(n_hid, n_head_dim * head)  # å®šä¹‰é”®æƒé‡çŸ©é˜µï¼Œç»´åº¦ä¸º n_hid åˆ° n_head_dim * head

        for m in [self.Wq, self.Wk]:  # å¯¹æƒé‡çŸ©é˜µè¿›è¡Œåˆå§‹åŒ–
            if isinstance(m, nn.Linear):  # å¦‚æœå­æ¨¡å—æ˜¯å…¨è¿æ¥å±‚
                nn.init.xavier_normal_(m.weight.data)  # ä½¿ç”¨ Xavier æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
                m.bias.data.fill_(0.1)  # å°†åç½®åˆå§‹åŒ–ä¸º 0.1

    def forward(self, inputs):  # inputs: [B, N, T(features)]
        """
        å‰å‘ä¼ æ’­
        :param inputs: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º [B, N, T]ï¼ˆæ‰¹é‡å¤§å°ï¼ŒèŠ‚ç‚¹æ•°é‡ï¼Œç‰¹å¾æ•°é‡ï¼‰
        :return: æ³¨æ„åŠ›æƒé‡çŸ©é˜µ
        """
        X = self.mlp1(inputs)  # é€šè¿‡ MLP æ¨¡å‹å¤„ç†è¾“å…¥æ•°æ®
        Xq = self.Wq(X)  # è®¡ç®—æŸ¥è¯¢å‘é‡
        Xk = self.Wk(X)  # è®¡ç®—é”®å‘é‡

        # è·å–è¾“å…¥çš„ç»´åº¦ä¿¡æ¯
        B, N, n_hid = Xq.shape  # è·å–æ‰¹é‡å¤§å° Bï¼ŒèŠ‚ç‚¹æ•°é‡ Nï¼Œéšè—å±‚ç»´åº¦ n_hid

        # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
        # è°ƒæ•´æŸ¥è¯¢å’Œé”®å‘é‡çš„å½¢çŠ¶ä»¥é€‚åº”å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
        Xq = Xq.view(B, N, self.head, self.n_head_dim)  # é‡å¡‘æŸ¥è¯¢å‘é‡ï¼Œå½¢çŠ¶ä¸º [B, N, head, head_dim]
        Xk = Xk.view(B, N, self.head, self.n_head_dim)  # é‡å¡‘é”®å‘é‡ï¼Œå½¢çŠ¶ä¸º [B, N, head, head_dim]

        # è°ƒæ•´ç»´åº¦é¡ºåºï¼Œä¾¿äºåç»­çš„çŸ©é˜µä¹˜æ³•æ“ä½œ
        Xq = Xq.permute(0, 2, 1, 3)  # è°ƒæ•´ç»´åº¦é¡ºåºï¼Œå½¢çŠ¶ä¸º [B, head, N, head_dim]
        Xk = Xk.permute(0, 2, 1, 3)  # è°ƒæ•´ç»´åº¦é¡ºåºï¼Œå½¢çŠ¶ä¸º [B, head, N, head_dim]

        # è®¡ç®—æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼Œä½¿ç”¨çŸ©é˜µä¹˜æ³•å°†æŸ¥è¯¢å‘é‡å’Œé”®å‘é‡ç›¸ä¹˜ï¼Œå¹¶å¯¹æœ€åä¸¤ä¸ªç»´åº¦è¿›è¡Œè½¬ç½®
        probs = torch.matmul(Xq, Xk.transpose(-1, -2))  # è®¡ç®—æ³¨æ„åŠ›æƒé‡çŸ©é˜µ    Relation Inference,Figure3ä¸­çš„å…³ç³»æ¨æ–­
        return probs # è¿”å›æ³¨æ„åŠ›æƒé‡çŸ©é˜µ

# å®šä¹‰ä¸€ä¸ªå¸¦æœ‰å›¾å·ç§¯æ“ä½œçš„ GRU å•å…ƒï¼ˆDCGRU å•å…ƒï¼‰***Decoder***
"""
Figure3ä¸­çš„Decoderéƒ¨åˆ†,å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç³»åˆ—é‡å»ºæ¨¡å—å°†æ½œåœ¨å‘é‡Zè½¬æ¢å›æ—¶é—´åºåˆ—æ•°æ®,å¹¶ä½¿ç”¨å­¦ä¹ åˆ°çš„å›¾ç»“æ„é‡å»ºæ•°æ®
ä»æ—¶ç©ºæ•°æ®ä¸­æå–ç‰¹å¾ï¼Œè®¡ç®—æ›´æ–°å’Œé‡ç½®é—¨ï¼Œå¹¶æ›´æ–°éšè—çŠ¶æ€ï¼Œé€šè¿‡å›¾å·ç§¯å®ç°æ—¶ç©ºä¾èµ–å…³ç³»çš„æ•æ‰å’Œå»ºæ¨¡ã€‚
"""
class DCGRUCell_(torch.nn.Module):
    def __init__(self, device, num_units, max_diffusion_step, num_nodes, nonlinearity='tanh',
                 filter_type="laplacian", use_gc_for_ru=True):
        """
        åˆå§‹åŒ– DCGRU å•å…ƒ
        :param device: è®¾å¤‡(CPU æˆ– GPU)
        :param num_units: å•å…ƒæ•°
        :param max_diffusion_step: æœ€å¤§æ‰©æ•£æ­¥æ•°
        :param num_nodes: èŠ‚ç‚¹æ•°é‡
        :param nonlinearity: éçº¿æ€§æ¿€æ´»å‡½æ•°('tanh' æˆ– 'relu')
        :param filter_type: å›¾å·ç§¯æ»¤æ³¢å™¨ç±»å‹('laplacian' æˆ–å…¶ä»–ï¼‰
        :param use_gc_for_ru: æ˜¯å¦ä½¿ç”¨å›¾å·ç§¯æ¥è®¡ç®—æ›´æ–°å’Œé‡ç½®é—¨
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        self._activation = torch.tanh if nonlinearity == 'tanh' else torch.relu  # æ ¹æ® nonlinearity é€‰æ‹©æ¿€æ´»å‡½æ•°
        self.device = device  # è®¾ç½®è®¾å¤‡
        self._num_nodes = num_nodes  # è®¾ç½®èŠ‚ç‚¹æ•°é‡
        self._num_units = num_units  # è®¾ç½®å•å…ƒæ•°é‡
        self._max_diffusion_step = max_diffusion_step  # è®¾ç½®æœ€å¤§æ‰©æ•£æ­¥æ•°
        self._supports = []  # åˆå§‹åŒ–æ”¯æŒçš„å›¾å·ç§¯åˆ—è¡¨
        self._use_gc_for_ru = use_gc_for_ru  # è®¾ç½®æ˜¯å¦ä½¿ç”¨å›¾å·ç§¯è®¡ç®—æ›´æ–°å’Œé‡ç½®é—¨

        # å®šä¹‰ç”¨äºå›¾å·ç§¯çš„çº¿æ€§å±‚
        # è¾“å…¥æ˜¯ self._num_units * 2 * (self._max_diffusion_step + 1),è¾“å‡ºæ˜¯ self._num_units * 2
        # _gconv_0å’Œ_gconv_1ç”¨äºè®¡ç®—æ›´æ–°é—¨å’Œé‡ç½®é—¨ï¼Œ_gconv_c_0å’Œ_gconv_c_1ç”¨äºè®¡ç®—å€™é€‰éšè—çŠ¶æ€
        self._gconv_0 = nn.Linear(self._num_units * 2 * (self._max_diffusion_step + 1), self._num_units * 2)  # å®šä¹‰ç¬¬ä¸€ä¸ªå›¾å·ç§¯å±‚
        self._gconv_1 = nn.Linear(self._num_units * 2 * (self._max_diffusion_step + 1), self._num_units * 2)  # å®šä¹‰ç¬¬äºŒä¸ªå›¾å·ç§¯å±‚
        self._gconv_c_0 = nn.Linear(self._num_units * 2 * (self._max_diffusion_step + 1), self._num_units)  # å®šä¹‰ç¬¬ä¸‰ä¸ªå›¾å·ç§¯å±‚ï¼Œç”¨äºè®¡ç®—æ–°çš„éšè—çŠ¶æ€
        self._gconv_c_1 = nn.Linear(self._num_units * 2 * (self._max_diffusion_step + 1), self._num_units)  # å®šä¹‰ç¬¬å››ä¸ªå›¾å·ç§¯å±‚ï¼Œç”¨äºè®¡ç®—æ–°çš„éšè—çŠ¶æ€
        for m in self.modules():  # éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å­æ¨¡å—
            if isinstance(m, nn.Linear):  # å¦‚æœå­æ¨¡å—æ˜¯å…¨è¿æ¥å±‚
                nn.init.xavier_normal_(m.weight.data)  # ä½¿ç”¨ Xavier æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
                m.bias.data.fill_(0.1)  # å°†åç½®åˆå§‹åŒ–ä¸º 0.1

    def forward(self, inputs, hx, adj):
        """
        å‰å‘ä¼ æ’­
        :param inputs: å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥æ•°æ®
        :param hx: ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€
        :param adj: å½“å‰å›¾çš„é‚»æ¥çŸ©é˜µ
        :return: æ›´æ–°åçš„éšè—çŠ¶æ€
        """
        output_size = 2 * self._num_units  # è¾“å‡ºå¤§å°ä¸ºå•å…ƒæ•°é‡çš„ä¸¤å€
        if self._use_gc_for_ru:
            fn = self._gconv  # å¦‚æœä½¿ç”¨å›¾å·ç§¯è®¡ç®—æ›´æ–°å’Œé‡ç½®é—¨ï¼Œåˆ™ä½¿ç”¨å›¾å·ç§¯å‡½æ•°
        else:
            fn = self._fc  # å¦åˆ™ä½¿ç”¨å…¨è¿æ¥å‡½æ•°
        value = torch.sigmoid(fn(inputs, adj, hx, output_size, bias_start=1.0))  # è®¡ç®—æ›´æ–°å’Œé‡ç½®é—¨çš„å€¼

        value = torch.reshape(value, (-1, self._num_nodes, output_size))  # é‡å¡‘å€¼çš„å½¢çŠ¶
        # rï¼šé‡ç½®é—¨ï¼Œç”¨äºå†³å®šæ˜¯å¦å¿˜è®°ä¹‹å‰çš„ä¿¡æ¯ï¼›uï¼šæ›´æ–°é—¨ï¼Œç”¨äºæ§åˆ¶ä¿¡æ¯ä»å½“å‰è¾“å…¥å’Œå‰ä¸€éšè—çŠ¶æ€ä¼ é€’çš„æ¯”ä¾‹
        # r,uå¯¹åº”3.6ä¸­çš„rt'å’Œut'
        r, u = torch.split(tensor=value, split_size_or_sections=self._num_units, dim=-1)  # åˆ†å‰²æ›´æ–°å’Œé‡ç½®é—¨çš„å€¼
        r = torch.reshape(r, (-1, self._num_nodes * self._num_units))  # é‡å¡‘é‡ç½®é—¨çš„å€¼
        u = torch.reshape(u, (-1, self._num_nodes * self._num_units))  # é‡å¡‘æ›´æ–°é—¨çš„å€¼

        # r * hxå°†é‡ç½®é—¨çš„è¾“å‡ºå’Œéšè—çŠ¶æ€ç›¸ä¹˜ï¼Œè°ƒæ•´éšè—çŠ¶æ€ä¸­çš„ä¿¡æ¯
        # cï¼šå€™é€‰æ–°çš„éšè—çŠ¶æ€ï¼Œé€šè¿‡å›¾å·ç§¯_gconv_cè®¡ç®—å¾—åˆ°,å¯¹åº”3.6å…¬å¼ä¸­çš„ct'
        c = self._gconv_c(inputs, adj, r * hx, self._num_units)  # é€šè¿‡å›¾å·ç§¯è®¡ç®—æ–°çš„éšè—çŠ¶æ€
        if self._activation is not None:
            c = self._activation(c)  # åº”ç”¨æ¿€æ´»å‡½æ•°

        new_state = u * hx + (1.0 - u) * c  # è®¡ç®—æ–°çš„éšè—çŠ¶æ€,å¯¹åº”3.6å…¬å¼ä¸­çš„hgt
        return new_state

    @staticmethod
    def _build_sparse_matrix(L):
        """
        æ„å»ºç¨€ç–çŸ©é˜µ
        :param L: è¾“å…¥çŸ©é˜µ
        :return: æ„å»ºåçš„ç¨€ç–çŸ©é˜µ
        """
        L = L.tocoo()  # å°†çŸ©é˜µè½¬æ¢ä¸º COOrdinate æ ¼å¼
        indices = np.column_stack((L.row, L.col))  # è·å–çŸ©é˜µçš„è¡Œåˆ—ç´¢å¼•
        indices = indices[np.lexsort((indices[:, 0], indices[:, 1]))]  # æŒ‰è¡Œåˆ—æ’åºç´¢å¼•
        L = torch.sparse_coo_tensor(indices.T, L.data, L.shape, device=device)  # æ„å»ºç¨€ç–å¼ é‡
        return L

    def _calculate_random_walk_matrix(self, adj_mx):
        """
        è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µ
        :param adj_mx: é‚»æ¥çŸ©é˜µ
        :return: éšæœºæ¸¸èµ°çŸ©é˜µ
        """
        adj_mx = adj_mx + torch.eye(int(adj_mx.shape[0])).to(self.device)  # åœ¨é‚»æ¥çŸ©é˜µä¸ŠåŠ å•ä½çŸ©é˜µ
        d = torch.sum(adj_mx, 1)  # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„åº¦
        d_inv = 1. / d  # è®¡ç®—åº¦çš„å€’æ•°
        d_inv = torch.where(torch.isinf(d_inv), torch.zeros(d_inv.shape).to(self.device), d_inv)  # å¤„ç†æ— ç©·å¤§çš„æƒ…å†µ
        d_mat_inv = torch.diag(d_inv)  # æ„å»ºåº¦çš„å€’æ•°å¯¹è§’çŸ©é˜µ
        random_walk_mx = torch.mm(d_mat_inv, adj_mx)  # è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µ
        return random_walk_mx

    def _calculate_random_walk0(self, adj_mx, B):
        """
        è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µï¼Œé€‚ç”¨äºæ‰¹é‡æ“ä½œ
        æ”¯æŒæ‰¹å¤„ç†çš„éšæœºæ¸¸èµ°è®¡ç®—
        :param adj_mx: é‚»æ¥çŸ©é˜µ
        :param B: æ‰¹é‡å¤§å°
        :return: éšæœºæ¸¸èµ°çŸ©é˜µ
        """
        adj_mx = adj_mx + torch.eye(int(adj_mx.shape[1])).unsqueeze(0).repeat(B, 1, 1).to(self.device)  # åœ¨é‚»æ¥çŸ©é˜µä¸ŠåŠ å•ä½çŸ©é˜µï¼Œå¹¶æ‰©å±•ä¸ºæ‰¹é‡å¤§å°
        d = torch.sum(adj_mx, 1)  # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„åº¦
        d_inv = 1. / d  # è®¡ç®—åº¦çš„å€’æ•°
        d_inv = torch.where(torch.isinf(d_inv), torch.zeros(d_inv.shape).to(self.device), d_inv)  # å¤„ç†æ— ç©·å¤§çš„æƒ…å†µ
        d_mat_inv = torch.diag_embed(d_inv)  # æ„å»ºåº¦çš„å€’æ•°å¯¹è§’çŸ©é˜µ
        random_walk_mx = torch.matmul(d_mat_inv, adj_mx)  # è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µ
        return random_walk_mx

    @staticmethod
    def _concat(x, x_):
        """
        è¿æ¥ä¸¤ä¸ªå¼ é‡
        :param x: å¼ é‡ x
        :param x_: å¼ é‡ x_
        :return: è¿æ¥åçš„å¼ é‡
        """
        x_ = x_.unsqueeze(0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦
        return torch.cat([x, x_], dim=0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šè¿æ¥ä¸¤ä¸ªå¼ é‡

    def _fc(self, inputs, state, output_size, bias_start=0.0):
        """
        å…¨è¿æ¥å±‚æ“ä½œ
        :param inputs: è¾“å…¥æ•°æ®
        :param state: éšè—çŠ¶æ€
        :param output_size: è¾“å‡ºå¤§å°
        :param bias_start: åç½®çš„åˆå§‹å€¼
        :return: è®¡ç®—åçš„å€¼
        """
        batch_size = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        inputs = torch.reshape(inputs, (batch_size * self._num_nodes, -1))  # é‡å¡‘è¾“å…¥æ•°æ®çš„å½¢çŠ¶
        state = torch.reshape(state, (batch_size * self._num_nodes, -1))  # é‡å¡‘éšè—çŠ¶æ€çš„å½¢çŠ¶
        inputs_and_state = torch.cat([inputs, state], dim=-1)  # è¿æ¥è¾“å…¥æ•°æ®å’Œéšè—çŠ¶æ€
        input_size = inputs_and_state.shape[-1]  # è·å–è¾“å…¥å¤§å°
        weights = self._fc_params.get_weights((input_size, output_size))  # è·å–å…¨è¿æ¥å±‚çš„æƒé‡
        value = torch.sigmoid(torch.matmul(inputs_and_state, weights))  # è®¡ç®—å…¨è¿æ¥å±‚çš„è¾“å‡ºï¼Œå¹¶åº”ç”¨ sigmoid å‡½æ•°
        biases = self._fc_params.get_biases(output_size, bias_start)  # è·å–å…¨è¿æ¥å±‚çš„åç½®
        value += biases  # åŠ ä¸Šåç½®
        return value

    def _gconv(self, inputs, adj_mx, state, output_size, bias_start=0.0):
        """
        å›¾å·ç§¯æ“ä½œ
        :param inputs: è¾“å…¥æ•°æ®
        :param adj_mx: é‚»æ¥çŸ©é˜µ
        :param state: éšè—çŠ¶æ€
        :param output_size: è¾“å‡ºå¤§å°
        :param bias_start: åç½®çš„åˆå§‹å€¼
        :return: è®¡ç®—åçš„å€¼
        """
        B = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        adj_mx0 = self._calculate_random_walk0(adj_mx, B)  # è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µ
        adj_mx1 = self._calculate_random_walk0(adj_mx.permute(0, 2, 1), B)  # è®¡ç®—è½¬ç½®åçš„éšæœºæ¸¸èµ°çŸ©é˜µ

        batch_size = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1))  # é‡å¡‘è¾“å…¥æ•°æ®çš„å½¢çŠ¶
        state = torch.reshape(state, (batch_size, self._num_nodes, -1))  # é‡å¡‘éšè—çŠ¶æ€çš„å½¢çŠ¶
        inputs_and_state = torch.cat([inputs, state], dim=2)  # è¿æ¥è¾“å…¥æ•°æ®å’Œéšè—çŠ¶æ€
        input_size = inputs_and_state.size(2)  # è·å–è¾“å…¥å¤§å°

        x = inputs_and_state  # [B, N, 2 * C]
        x0_0 = torch.unsqueeze(x, 0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦
        x1_0 = torch.unsqueeze(x, 0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦

        if self._max_diffusion_step == 0:  # å¦‚æœæœ€å¤§æ‰©æ•£æ­¥æ•°ä¸º0
            pass  # ä¸è¿›è¡Œæ‰©æ•£
        else:
            # å›¾å·ç§¯æ“ä½œ,å¯¹åº”3.6ä¸­çš„WQ*Ay
            x0_1 = torch.matmul(adj_mx0, x0_0)  # è®¡ç®—æ‰©æ•£æ­¥æ•°ä¸º1çš„å›¾å·ç§¯
            x1_1 = torch.matmul(adj_mx1, x1_0)  # è®¡ç®—è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º1çš„å›¾å·ç§¯
            x0_0 = torch.cat([x0_0, x0_1], dim=0)  # è¿æ¥æ‰©æ•£æ­¥æ•°ä¸º0å’Œ1çš„å›¾å·ç§¯ç»“æœ
            x1_0 = torch.cat([x1_0, x1_1], dim=0)  # è¿æ¥è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º0å’Œ1çš„å›¾å·ç§¯ç»“æœ

            for k in range(2, self._max_diffusion_step + 1):  # è®¡ç®—æ›´å¤§æ‰©æ•£æ­¥æ•°çš„å›¾å·ç§¯
                x0_2 = torch.matmul(adj_mx0, x0_1)  # è®¡ç®—æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯
                x1_2 = torch.matmul(adj_mx1, x1_1)  # è®¡ç®—è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯
                x0_0 = torch.cat([x0_0, x0_1], dim=0)  # è¿æ¥æ‰©æ•£æ­¥æ•°ä¸º0åˆ°kçš„å›¾å·ç§¯ç»“æœ
                x1_0 = torch.cat([x1_0, x1_1], dim=0)  # è¿æ¥è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º0åˆ°kçš„å›¾å·ç§¯ç»“æœ
                x0_1 = x0_2  # æ›´æ–°æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯ç»“æœ
                x1_1 = x1_2  # æ›´æ–°è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯ç»“æœ

        num_matrices = self._max_diffusion_step + 1  # ç¡®å®šå›¾å·ç§¯çŸ©é˜µçš„æ•°é‡
        x0_0 = x0_0.permute(1, 2, 3, 0)  # è°ƒæ•´å›¾å·ç§¯ç»“æœçš„ç»´åº¦
        x1_0 = x1_0.permute(1, 2, 3, 0)  # è°ƒæ•´è½¬ç½®åçš„å›¾å·ç§¯ç»“æœçš„ç»´åº¦
        x0_0 = torch.reshape(x0_0, shape=[batch_size * self._num_nodes, input_size * num_matrices])  # é‡å¡‘å›¾å·ç§¯ç»“æœçš„å½¢çŠ¶
        x1_0 = torch.reshape(x1_0, shape=[batch_size * self._num_nodes, input_size * num_matrices])  # é‡å¡‘è½¬ç½®åçš„å›¾å·ç§¯ç»“æœçš„å½¢çŠ¶
        x0_0 = self._gconv_0(x0_0)  # è®¡ç®—å›¾å·ç§¯çš„è¾“å‡º
        x1_0 = self._gconv_1(x1_0)  # è®¡ç®—è½¬ç½®åå›¾å·ç§¯çš„è¾“å‡º

        return torch.reshape(x0_0 + x1_0, [batch_size, self._num_nodes * output_size])  # è¿”å›å›¾å·ç§¯çš„è¾“å‡º

    def _gconv_c(self, inputs, adj_mx, state, output_size, bias_start=0.0):
        """
        å›¾å·ç§¯æ“ä½œï¼Œç”¨äºè®¡ç®—æ–°çš„éšè—çŠ¶æ€
        :param inputs: è¾“å…¥æ•°æ®
        :param adj_mx: é‚»æ¥çŸ©é˜µ
        :param state: éšè—çŠ¶æ€
        :param output_size: è¾“å‡ºå¤§å°
        :param bias_start: åç½®çš„åˆå§‹å€¼
        :return: è®¡ç®—åçš„å€¼
        """
        B = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        adj_mx0 = self._calculate_random_walk0(adj_mx, B)  # è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µ
        adj_mx1 = self._calculate_random_walk0(adj_mx.permute(0, 2, 1), B)  # è®¡ç®—è½¬ç½®åçš„éšæœºæ¸¸èµ°çŸ©é˜µ

        batch_size = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1))  # é‡å¡‘è¾“å…¥æ•°æ®çš„å½¢çŠ¶
        state = torch.reshape(state, (batch_size, self._num_nodes, -1))  # é‡å¡‘éšè—çŠ¶æ€çš„å½¢çŠ¶
        inputs_and_state = torch.cat([inputs, state], dim=2)  # è¿æ¥è¾“å…¥æ•°æ®å’Œéšè—çŠ¶æ€
        input_size = inputs_and_state.size(2)  # è·å–è¾“å…¥å¤§å°

        x = inputs_and_state  # [B, N, 2 * C]
        x0_0 = torch.unsqueeze(x, 0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦
        x1_0 = torch.unsqueeze(x, 0)  # åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦

        if self._max_diffusion_step == 0:  # å¦‚æœæœ€å¤§æ‰©æ•£æ­¥æ•°ä¸º0
            pass  # ä¸è¿›è¡Œæ‰©æ•£
        else:
            x0_1 = torch.matmul(adj_mx0, x0_0)  # è®¡ç®—æ‰©æ•£æ­¥æ•°ä¸º1çš„å›¾å·ç§¯
            x1_1 = torch.matmul(adj_mx1, x1_0)  # è®¡ç®—è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º1çš„å›¾å·ç§¯
            x0_0 = torch.cat([x0_0, x0_1], dim=0)  # è¿æ¥æ‰©æ•£æ­¥æ•°ä¸º0å’Œ1çš„å›¾å·ç§¯ç»“æœ
            x1_0 = torch.cat([x1_0, x1_1], dim=0)  # è¿æ¥è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º0å’Œ1çš„å›¾å·ç§¯ç»“æœ

            for k in range(2, self._max_diffusion_step + 1):  # è®¡ç®—æ›´å¤§æ‰©æ•£æ­¥æ•°çš„å›¾å·ç§¯
                x0_2 = torch.matmul(adj_mx0, x0_1)  # è®¡ç®—æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯
                x1_2 = torch.matmul(adj_mx1, x1_1)  # è®¡ç®—è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯
                x0_0 = torch.cat([x0_0, x0_1], dim=0)  # è¿æ¥æ‰©æ•£æ­¥æ•°ä¸º0åˆ°kçš„å›¾å·ç§¯ç»“æœ
                x1_0 = torch.cat([x1_0, x1_1], dim=0)  # è¿æ¥è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸º0åˆ°kçš„å›¾å·ç§¯ç»“æœ
                x0_1 = x0_2  # æ›´æ–°æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯ç»“æœ
                x1_1 = x1_2  # æ›´æ–°è½¬ç½®åçš„æ‰©æ•£æ­¥æ•°ä¸ºkçš„å›¾å·ç§¯ç»“æœ

        num_matrices = self._max_diffusion_step + 1  # ç¡®å®šå›¾å·ç§¯çŸ©é˜µçš„æ•°é‡
        x0_0 = x0_0.permute(1, 2, 3, 0)  # è°ƒæ•´å›¾å·ç§¯ç»“æœçš„ç»´åº¦
        x1_0 = x1_0.permute(1, 2, 3, 0)  # è°ƒæ•´è½¬ç½®åçš„å›¾å·ç§¯ç»“æœçš„ç»´åº¦
        x0_0 = torch.reshape(x0_0, shape=[batch_size * self._num_nodes, input_size * num_matrices])  # é‡å¡‘å›¾å·ç§¯ç»“æœçš„å½¢çŠ¶
        x1_0 = torch.reshape(x1_0, shape=[batch_size * self._num_nodes, input_size * num_matrices])  # é‡å¡‘è½¬ç½®åçš„å›¾å·ç§¯ç»“æœçš„å½¢çŠ¶
        x0_0 = self._gconv_c_0(x0_0)  # è®¡ç®—å›¾å·ç§¯çš„è¾“å‡º
        x1_0 = self._gconv_c_1(x1_0)  # è®¡ç®—è½¬ç½®åå›¾å·ç§¯çš„è¾“å‡º

        return torch.reshape(x0_0 + x1_0, [batch_size, self._num_nodes * output_size])  # è¿”å›å›¾å·ç§¯çš„è¾“å‡º


# å®šä¹‰ç¼–ç å™¨æ¨¡å‹
"""
å®ç°äº†ä¸€ä¸ªåŸºäºå›¾å·ç§¯é—¨æ§å•å…ƒ(DCGRU)çš„ç¼–ç å™¨æ¨¡å‹,ä¸»è¦ç”¨äºå¤„ç†æ—¶é—´åºåˆ—æ•°æ®å’Œå›¾ç»“æ„æ•°æ®ã€‚
å°†è¾“å…¥æ•°æ®ä¸å›¾çš„é‚»æ¥çŸ©é˜µç›¸ç»“åˆ,å­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»,é€šè¿‡å¾ªç¯ç½‘ç»œå±‚è¿›è¡Œæ—¶é—´åºåˆ—å»ºæ¨¡ã€‚
"""
class EncoderModel(nn.Module):
    def __init__(self, device, n_dim, n_hid, max_diffusion_step, num_nodes, num_rnn_layers, filter_type):
        """
        åˆå§‹åŒ–ç¼–ç å™¨æ¨¡å‹
        :param device: è®¾å¤‡(CPU æˆ– GPU)
        :param n_dim: è¾“å…¥ç»´åº¦
        :param n_hid: éšè—å±‚ç»´åº¦
        :param max_diffusion_step: æœ€å¤§æ‰©æ•£æ­¥æ•°
        :param num_nodes: èŠ‚ç‚¹æ•°é‡
        :param num_rnn_layers: RNN å±‚æ•°
        :param filter_type: æ»¤æ³¢å™¨ç±»å‹
        """
        super(EncoderModel, self).__init__()
        self.device = device  # è®¾å¤‡
        self.input_dim = n_dim  # è¾“å…¥ç»´åº¦
        self.rnn_units = n_hid  # éšè—å±‚ç»´åº¦
        self.max_diffusion_step = max_diffusion_step  # æœ€å¤§æ‰©æ•£æ­¥æ•°
        self.num_nodes = num_nodes  # èŠ‚ç‚¹æ•°é‡
        self.num_rnn_layers = num_rnn_layers  # RNN å±‚æ•°
        self.filter_type = filter_type  # æ»¤æ³¢å™¨ç±»å‹
        # # å®šä¹‰æ¯å±‚çš„éšè—çŠ¶æ€å¤§å°ï¼šèŠ‚ç‚¹æ•° * éšè—å•å…ƒæ•°
        self.hidden_state_size = self.num_nodes * self.rnn_units  # éšè—çŠ¶æ€å¤§å°
        # åˆ›å»ºäº†num_rnn_layersä¸ªDCGRUå•å…ƒ,æ¯å±‚ç”¨äºå¤„ç†è¾“å…¥æ•°æ®å’Œé‚»æ¥çŸ©é˜µ,å¹¶é€å±‚é€’å½’æ›´æ–°éšè—çŠ¶æ€
        self.dcgru_layers = nn.ModuleList(
            [DCGRUCell_(self.device, self.rnn_units, self.max_diffusion_step, self.num_nodes,
                       filter_type=self.filter_type) for _ in range(self.num_rnn_layers)])  # å®šä¹‰å¤šä¸ª DCGRU å•å…ƒ

    def forward(self, inputs, adj, hidden_state=None):
        """
        å‰å‘ä¼ æ’­
        :param inputs: è¾“å…¥æ•°æ®
        :param adj: é‚»æ¥çŸ©é˜µ
        :param hidden_state: éšè—çŠ¶æ€
        :return: è¾“å‡ºå’Œéšè—çŠ¶æ€
        """
        batch_size = inputs.shape[0]  # è·å–æ‰¹é‡å¤§å°
        if hidden_state is None:
            # å¦‚æœæ²¡æœ‰æä¾›éšè—çŠ¶æ€ï¼Œåˆ™åˆå§‹åŒ–ä¸ºå…¨é›¶
            hidden_state = torch.zeros((self.num_rnn_layers, batch_size, self.hidden_state_size)).to(self.device)  # åˆå§‹åŒ–éšè—çŠ¶æ€
        hidden_states = []  # ç”¨äºå­˜å‚¨æ¯ä¸€å±‚çš„éšè—çŠ¶æ€
        output = inputs  # è¾“å…¥æ•°æ®ä½œä¸ºåˆå§‹çš„è¾“å‡º

        # é€å±‚å¤„ç†æ•°æ®
        for layer_num, dcgru_layer in enumerate(self.dcgru_layers):
            # è°ƒç”¨æ¯ä¸€å±‚ DCGRUï¼Œè®¡ç®—è¾“å‡ºå’Œæ›´æ–°éšè—çŠ¶æ€
            next_hidden_state = dcgru_layer(output, hidden_state[layer_num], adj)  # è®¡ç®—ä¸‹ä¸€ä¸ªéšè—çŠ¶æ€
            hidden_states.append(next_hidden_state)  # ä¿å­˜æ¯ä¸€å±‚çš„éšè—çŠ¶æ€
            output = next_hidden_state  # æ›´æ–°è¾“å‡ºï¼Œå°†å…¶ä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥

        # è¿”å›æœ€åä¸€å±‚çš„è¾“å‡ºå’Œæ‰€æœ‰éšè—çŠ¶æ€
        return output, torch.stack(hidden_states)

# å®šä¹‰ GRELEN æ¨¡å‹
class Grelen(nn.Module):
    """
    GRELEN Model.
    """
    def __init__(self, device, T, target_T, Graph_learner_n_hid, Graph_learner_n_head_dim, Graph_learner_head, temperature,
                 hard, GRU_n_dim, max_diffusion_step, num_nodes, num_rnn_layers, filter_type, do_prob=0.):
        """
        åˆå§‹åŒ– GRELEN æ¨¡å‹
        :param device: è®¾å¤‡(CPU æˆ– GPU)
        :param T: è¾“å…¥åºåˆ—é•¿åº¦
        :param target_T: ç›®æ ‡åºåˆ—é•¿åº¦
        :param Graph_learner_n_hid: å›¾å­¦ä¹ å™¨éšè—å±‚ç»´åº¦
        :param Graph_learner_n_head_dim: å›¾å­¦ä¹ å™¨å¤´ç»´åº¦
        :param Graph_learner_head: å›¾å­¦ä¹ å™¨å¤´æ•°é‡
        :param temperature: Gumbel-softmax æ¸©åº¦å‚æ•°
        :param hard: æ˜¯å¦ä½¿ç”¨ç¡¬ Gumbel-softmax
        :param GRU_n_dim: GRU éšè—å±‚ç»´åº¦
        :param max_diffusion_step: æœ€å¤§æ‰©æ•£æ­¥æ•°
        :param num_nodes: èŠ‚ç‚¹æ•°é‡
        :param num_rnn_layers: RNN å±‚æ•°
        :param filter_type: æ»¤æ³¢å™¨ç±»å‹
        :param do_prob: dropout æ¦‚ç‡
        """
        super(Grelen, self).__init__()  # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        self.device = device  # è®¾ç½®æ¨¡å‹è¿è¡Œçš„è®¾å¤‡
        self.len_sequence = T  # è®¾ç½®è¾“å…¥åºåˆ—é•¿åº¦
        self.target_T = target_T  # è®¾ç½®é¢„æµ‹çš„ç›®æ ‡åºåˆ—é•¿åº¦

        # åˆå§‹åŒ–å›¾å­¦ä¹ å™¨ï¼Œè´Ÿè´£å­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ï¼ˆRelation Inference éƒ¨åˆ†ï¼‰
        # é€šè¿‡è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„qå’Œkç¡®å®šèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œç”Ÿæˆå›¾ç»“æ„çš„æ¦‚ç‡ã€‚
        self.graph_learner = Graph_learner(T, Graph_learner_n_hid, Graph_learner_n_head_dim, Graph_learner_head, do_prob)
        
        # ç”¨äºè¾“å…¥æ—¶åºæ•°æ®æŠ•å½±çš„çº¿æ€§å±‚ï¼ŒæŠ•å½±ç»´åº¦ä¸º GRU çš„éšè—ç»´åº¦
        self.linear1 = nn.Linear(1, GRU_n_dim)
        
        # åˆå§‹åŒ–çº¿æ€§å±‚çš„æƒé‡ï¼Œä½¿ç”¨ Xavier æ­£æ€åˆ†å¸ƒ
        nn.init.xavier_normal_(self.linear1.weight.data)
        
        # å°†åç½®åˆå§‹åŒ–ä¸º 0.1
        self.linear1.bias.data.fill_(0.1)

        self.temperature = temperature  # Gumbel-softmax çš„æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶é‡‡æ ·çš„â€œéšæœºæ€§â€
        self.hard = hard  # æ˜¯å¦ä½¿ç”¨ç¡¬ Gumbel-softmax
        self.GRU_n_dim = GRU_n_dim  # GRU éšè—å±‚çš„ç»´åº¦
        self.num_nodes = num_nodes  # å›¾çš„èŠ‚ç‚¹æ•°é‡
        self.head = Graph_learner_head  # å›¾å­¦ä¹ å™¨çš„å¤´æ•°é‡

        # å®šä¹‰å¤šä¸ª EncoderModel æ¨¡å‹ï¼Œç”¨äºå¯¹è¾“å…¥æ•°æ®è¿›è¡Œç¼–ç ï¼Œæ¯ä¸ªå›¾å­¦ä¹ å¤´éƒ½å¯¹åº”ä¸€ä¸ª EncoderModel
        # ç¼–ç å™¨ä»è¾“å…¥æ—¶åºæ•°æ®ä¸­æå–ç‰¹å¾,ç”±å¤šä¸ªEncoderModelæ¨¡å—ç»„æˆ,å¤„ç†å¤šå¤´æ³¨æ„åŠ›çš„å›¾ç»“æ„ã€‚
        self.encoder_model = nn.ModuleList(
            [EncoderModel(self.device, GRU_n_dim, GRU_n_dim, max_diffusion_step, num_nodes, num_rnn_layers, filter_type)
             for _ in range(self.head - 1)]
        )

        # å®šä¹‰è¾“å‡ºå±‚ï¼Œç”¨äºå°†ç¼–ç ç»“æœè¾“å‡ºä¸ºæ—¶é—´åºåˆ—é¢„æµ‹ç»“æœ
        self.linear_out = nn.Linear(GRU_n_dim, 1)
        
        # åˆå§‹åŒ–è¾“å‡ºå±‚çš„æƒé‡ï¼Œä½¿ç”¨ Xavier æ­£æ€åˆ†å¸ƒ
        nn.init.xavier_normal_(self.linear_out.weight.data)
        
        # åˆå§‹åŒ–è¾“å‡ºå±‚çš„åç½®ä¸º 0.1
        self.linear_out.bias.data.fill_(0.1)

    def _compute_sampling_threshold(self, batches_seen):
        """
        åŠ¨æ€è®¡ç®—é‡‡æ ·é˜ˆå€¼ï¼Œéšç€è®­ç»ƒè¿›è¡ŒåŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥
        :param batches_seen: å·²è§æ‰¹æ¬¡
        :return: é‡‡æ ·é˜ˆå€¼
        """
        return self.cl_decay_steps / (
            self.cl_decay_steps + np.exp(batches_seen / self.cl_decay_steps))

    def encoder(self, inputs, adj, head):
        """
        ç¼–ç å™¨çš„å‰å‘ä¼ æ’­
        :param inputs: è¾“å…¥æ•°æ®ï¼ˆå½¢çŠ¶ä¸º B x N x T)
        :param adj: é‚»æ¥çŸ©é˜µï¼ˆè¡¨ç¤ºå›¾ç»“æ„ï¼‰
        :param head: å›¾å­¦ä¹ å™¨çš„å¤´ç¼–å·
        :return: ç¼–ç åçš„éšè—çŠ¶æ€å¼ é‡
        """
        encoder_hidden_state = None  # åˆå§‹åŒ–éšè—çŠ¶æ€
        encoder_hidden_state_tensor = torch.zeros(inputs.shape).to(self.device)  # åˆå§‹åŒ–å­˜å‚¨éšè—çŠ¶æ€çš„å¼ é‡

        # å¯¹æ¯ä¸€ä¸ªæ—¶é—´æ­¥æ‰§è¡Œç¼–ç æ“ä½œ
        for t in range(self.len_sequence):
            # è°ƒç”¨å¯¹åº”å¤´ç¼–å·çš„ç¼–ç å™¨æ¨¡å‹è¿›è¡Œç¼–ç ï¼Œæ›´æ–°éšè—çŠ¶æ€
            _, encoder_hidden_state = self.encoder_model[head](inputs[..., t], adj, encoder_hidden_state)
            # å°†ç¼–ç åçš„éšè—çŠ¶æ€ä¿å­˜åˆ°å¼ é‡ä¸­
            encoder_hidden_state_tensor[..., t] = encoder_hidden_state[-1, ...].reshape(-1, self.num_nodes, self.GRU_n_dim)

        return encoder_hidden_state_tensor  # è¿”å›ç¼–ç åçš„éšè—çŠ¶æ€å¼ é‡

    def forward(self, inputs):
        """
        å‰å‘ä¼ æ’­
        :param inputs: è¾“å…¥æ•°æ®
        :return: æ¦‚ç‡å’Œè¾“å‡º
        """
        B = inputs.shape[0]  # è·å–è¾“å…¥æ‰¹é‡å¤§å°
        input_projected = self.linear1(inputs.unsqueeze(-1))  # é€šè¿‡çº¿æ€§å±‚å¯¹è¾“å…¥è¿›è¡ŒæŠ•å½±
        input_projected = input_projected.permute(0, 1, 3, 2)  # è°ƒæ•´ç»´åº¦é¡ºåºä»¥é€‚åº”æ¨¡å‹çš„è¾“å…¥æ ¼å¼

        # é€šè¿‡å›¾å­¦ä¹ å™¨è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»æ¦‚ç‡ï¼ˆå›¾ä¸­çš„ Relation Inferenceï¼‰
        probs = self.graph_learner(inputs)

        # æ„å»ºæ©ç çŸ©é˜µï¼Œç”¨äºå»é™¤å›¾ä¸­èŠ‚ç‚¹ä¸è‡ªå·±çš„è¿æ¥
        # ç”Ÿæˆä¸€ä¸ªå¯¹è§’çº¿ä¸ºTrue,å…¶ä»–éƒ¨åˆ†ä¸ºfalseçš„æ©ç çŸ©é˜µmask_loc,ç”¨äºå¿½ç•¥è‡ªå·±è¿æ¥(èŠ‚ç‚¹ä¸è‡ªå·±çš„è¿æ¥)
        mask_loc = torch.eye(self.num_nodes, dtype=bool).to(self.device)
        # å»é™¤å¯¹è§’çº¿çš„å…ƒç´ ï¼Œè·å–èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥æ¦‚ç‡
        probs_reshaped = probs.masked_select(~mask_loc).view(B, self.head, self.num_nodes * (self.num_nodes - 1)).to(self.device)
        probs_reshaped = probs_reshaped.permute(0, 2, 1)

        # å¯¹è¿æ¥æ¦‚ç‡åº”ç”¨ softmaxï¼Œå°†æƒé‡å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ
        prob = F.softmax(probs_reshaped, -1)

        # é€šè¿‡ Gumbel-softmax è¿›è¡Œé‡‡æ ·ï¼Œç¡®å®šæœ€ç»ˆçš„å›¾ç»“æ„
        edges = gumbel_softmax(torch.log(prob + 1e-5), tau=self.temperature, hard=True).to(self.device)
        # è®¡ç®—å‡ºçš„å›¾å…³ç³»é€šè¿‡Gumbel-softmaxè¿›è¡Œé‡‡æ ·,é‡‡æ ·åçš„ç»“æ„å˜ä¸ºæ½œåœ¨å˜é‡z,ç”¨ä»¥ç¡®å®šèŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥
        # **å¯¹åº”å›¾ä¸­çš„sampling**

        # åˆå§‹åŒ–é‚»æ¥çŸ©é˜µåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªå¤´çš„é‚»æ¥çŸ©é˜µ
        adj_list = torch.ones(self.head, B, self.num_nodes, self.num_nodes).to(self.device)
        # æ„å»ºæ©ç ï¼Œç”¨äºå¿½ç•¥å¯¹è§’å…ƒç´ ï¼ˆèŠ‚ç‚¹ä¸è‡ªèº«çš„è¿æ¥ï¼‰
        mask = ~torch.eye(self.num_nodes, dtype=bool).unsqueeze(0).unsqueeze(0).to(self.device)
        mask = mask.repeat(self.head, B, 1, 1).to(self.device)

        # å°†é‡‡æ ·å¾—åˆ°çš„è¾¹å¡«å……åˆ°é‚»æ¥çŸ©é˜µä¸­
        adj_list[mask] = edges.permute(2, 0, 1).flatten()

        # åˆå§‹åŒ–è¾“å‡ºçŠ¶æ€å¼ é‡ï¼Œç”¨äºå­˜å‚¨ç¼–ç ç»“æœ
        state_for_output = torch.zeros(input_projected.shape).to(self.device)
        state_for_output = (state_for_output.unsqueeze(0)).repeat(self.head - 1, 1, 1, 1, 1)

        # å¯¹æ¯ä¸ªå¤´è¿›è¡Œç¼–ç 
        for head in range(self.head - 1):
            # è°ƒç”¨ç¼–ç å™¨è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œä»è¾“å…¥æ•°æ®ä¸­æå–æ—¶åºç‰¹å¾ï¼Œå¹¶åœ¨æ¯ä¸ªheadç”Ÿæˆå¯¹åº”çš„éšè—çŠ¶æ€hï¼Œå¹¶å°†ç¼–ç ç»“æœå­˜å‚¨åˆ° state_for_output ä¸­
            state_for_output[head, ...] = self.encoder(input_projected, adj_list[head + 1, ...], head)

        # state_for_output2å’Œoutputå¯¹åº”å›¾ä¸­çš„Decoderå’ŒSeries Reconstructionéƒ¨åˆ†
        # å°†ç¼–ç åçš„æ—¶åºç‰¹å¾é€šè¿‡çº¿æ€§å±‚è¿›è¡Œé‡æ„ï¼Œç”Ÿæˆé¢„æµ‹è¾“å‡º outputã€‚æ­¤è¿‡ç¨‹å¯¹åº”å›¾ä¸­çš„è§£ç å™¨å’Œåºåˆ—é‡æ„éƒ¨åˆ†ï¼Œå®ƒè´Ÿè´£å°†ç¼–ç åçš„ç‰¹å¾ï¼ˆæˆ–éšè—çŠ¶æ€ï¼‰è¿˜åŸä¸ºé¢„æµ‹çš„æ—¶é—´åºåˆ—ã€‚
        # å¯¹æ‰€æœ‰å¤´çš„ç¼–ç ç»“æœå–å¹³å‡å€¼ï¼Œå¹¶è°ƒæ•´ç»´åº¦
        state_for_output2 = torch.mean(state_for_output, 0).permute(0, 1, 3, 2)
        # é€šè¿‡è¾“å‡ºå±‚ç”Ÿæˆæœ€ç»ˆçš„é¢„æµ‹ç»“æœ
        output = self.linear_out(state_for_output2).squeeze(-1)[..., -1 - self.target_T:-1]

        # probè¡¨ç¤ºå›¾ç»“æ„çš„å­¦ä¹ ç»“æœ(å„èŠ‚ç‚¹çš„å…³ç³»),outputæ˜¯åŸºäºå›¾ç»“æ„è¿›è¡Œé¢„æµ‹çš„æ—¶é—´åºåˆ—
        return prob, output  # è¿”å›å›¾ç»“æ„çš„æ¦‚ç‡å’Œé¢„æµ‹çš„æ—¶é—´åºåˆ—ç»“æœ
