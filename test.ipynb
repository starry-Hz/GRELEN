{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/hz/code/GRELEN/test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.181.7.225/home/hz/code/GRELEN/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.181.7.225/home/hz/code/GRELEN/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.181.7.225/home/hz/code/GRELEN/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 读取 npz 文件\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取 npz 文件\n",
    "data = np.load('./data/SWAT/train_swat.npz')\n",
    "# ['train_x', 'train_target', 'val_x', 'val_target', 'mean', 'std']\n",
    "data.files\n",
    "# 获取 train_x 数组并查看其形状\n",
    "# train_x = data['train_x']\n",
    "# npy数据格式是一个四维的数组[N，H，W, C]，其中N代表数据集的总数，H, W，C分别代表每一张图片对应的长、宽、以及通道数。\n",
    "# # Original train_x shape: (4195, 51, 1, 30)\n",
    "# # print(\"Original train_x shape:\", train_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import *\n",
    "from config_files.SWAT_config_gcn import Config\n",
    "config = Config()\n",
    "\n",
    "# 从配置中获取参数\n",
    "device = config.device  # 设备\n",
    "batch_size = config.batch_size  # 批处理大小\n",
    "learning_rate = config.learning_rate  # 学习率\n",
    "epochs = config.epochs  # 训练周期数\n",
    "train_filename = config.train_filename  # 训练数据文件名\n",
    "train_loader, train_target_tensor, val_loader, val_target_tensor, _mean, _std = load_data_train(train_filename, device, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data['mean']  # 获取均值\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = data['std']  # 获取标准差\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swat_normal = pd.read_csv(\"data/SWAT/SWaT_Dataset_Normal_v1.csv\")\n",
    "swat_normal['Normal/Attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swat_abnormal = pd.read_csv(\"data/SWAT/SWaT_Dataset_Attack_v0.csv\")  # 读取异常的SWaT数据集\n",
    "# 新增一列 'Attack_Flag'，如果是 'Attack' 或 'A ttack' 则为 1，否则为 0\n",
    "swat_abnormal['Attack_Flag'] = swat_abnormal['Normal/Attack'].apply(lambda x: 1 if x in ['Attack', 'A ttack'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/SWAT/all_data_diffpool.npz'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config_files.SWAT_config import Config\n",
    "# 初始化配置对象，读取配置参数\n",
    "config = Config()\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_file = \"data/SWAT/\"\n",
    "data_path = os.path.join(data_file, 'all_data_diffpool.npz')\n",
    "\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.427057, 522.8467  ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ],\n",
       "       [  2.446274, 522.886   ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ],\n",
       "       [  2.489191, 522.8467  ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ],\n",
       "       ...,\n",
       "       [  2.531467, 520.6878  ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ],\n",
       "       [  2.521218, 520.7271  ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ],\n",
       "       [  2.501681, 521.1196  ,   2.      , ...,   1.      ,   1.      ,\n",
       "          0.      ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 读取异常的SWaT数据集\n",
    "swat_abnormal = pd.read_csv(\"data/SWAT/SWaT_Dataset_Attack_v0.csv\")\n",
    "\n",
    "# 新增一列 'Attack_Flag'，如果是 'Attack' 或 'A ttack' 则为 1，否则为 0\n",
    "swat_abnormal['Attack_Flag'] = swat_abnormal['Normal/Attack'].apply(lambda x: 1 if x in ['Attack', 'A ttack'] else 0)\n",
    "\n",
    "# 获取 'Normal/Attack' 列的索引\n",
    "col_index = swat_abnormal.columns.get_loc('Normal/Attack')\n",
    "\n",
    "# 将 'Attack_Flag' 插入到 'Normal/Attack' 列之前\n",
    "swat_abnormal.insert(col_index, 'Attack_Flag', swat_abnormal.pop('Attack_Flag'))\n",
    "swat_abnormal_np = np.array(swat_abnormal.iloc[:, 1: -1])\n",
    "swat_abnormal_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(449919, 52)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 查看数组的形状\n",
    "print(swat_abnormal_np.shape)\n",
    "\n",
    "# 查看最后一列的数据\n",
    "last_column = swat_abnormal_np[:, -1]\n",
    "print(last_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(mat, interval):\n",
    "    \"\"\"\n",
    "    对矩阵进行降采样,根据指定的间隔,将矩阵的行数缩减为每interval取一行。\n",
    "    :param mat: 输入的二维矩阵\n",
    "    :param interval: 采样间隔\n",
    "    :return: 降采样后的矩阵\n",
    "    \"\"\"\n",
    "    num_row, num_col = mat.shape  # 获取矩阵的行数和列数\n",
    "    res = num_row % interval  # 计算矩阵行数对采样间隔的余数\n",
    "    if res != 0:  # 如果行数不能被采样间隔整除\n",
    "        add_num = interval - res  # 计算需要补充的行数\n",
    "        add_mat = np.zeros((add_num, num_col))  # 创建一个全零的矩阵进行补充\n",
    "        mat = np.concatenate((mat, add_mat))  # 将原矩阵与补充的全零矩阵拼接在一起\n",
    "    num_row, num_col = mat.shape  # 获取补充后的矩阵的行数和列数\n",
    "    mat_tmp = np.zeros((interval, int(num_row / interval), num_col))  # 创建一个临时矩阵用于存储降采样数据\n",
    "    for i in range(interval):  # 遍历每个采样间隔\n",
    "        mat_tmp[i, ...] = mat[i::interval, :]  # 每隔interval行采样一次,存储到临时矩阵中\n",
    "    return np.mean(mat_tmp, 0)  # 对每个采样间隔的数据取均值,返回降采样后的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_norm(mat, max_=None, min_=None):\n",
    "    \"\"\"\n",
    "    对矩阵进行最大-最小归一化,将数据缩放到[0,1]区间。\n",
    "    :param mat: 输入矩阵\n",
    "    :param max_: 每列的最大值（可选）\n",
    "    :param min_: 每列的最小值（可选）\n",
    "    :return: 归一化后的矩阵,以及最大值和最小值\n",
    "    \"\"\"\n",
    "    if max_ is None:  # 如果没有提供最大值\n",
    "        max_ = np.max(mat, 0)  # 计算每列的最大值\n",
    "    if min_ is None:  # 如果没有提供最小值\n",
    "        min_ = np.min(mat, 0)  # 计算每列的最小值\n",
    "    nrow, ncol = mat.shape  # 获取矩阵的行数和列数\n",
    "    for i in range(ncol):  # 遍历每一列\n",
    "        if max_[i] == min_[i]:  # 如果最大值等于最小值\n",
    "            mat[:, i] = mat[:, i] - min_[i]  # 该列的所有值减去最小值\n",
    "        else:\n",
    "            mat[:, i] = (mat[:, i] - min_[i]) / (max_[i] - min_[i])  # 归一化处理：减去最小值并除以范围\n",
    "    return mat, max_, min_  # 返回归一化后的矩阵,最大值和最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swat_generate_data(xx, train_split, val_split, length, filename=None, max_=None, min_=None):\n",
    "    # 对输入数据进行最大-最小归一化处理\n",
    "    mat_, max_, min_ = max_min_norm(xx, max_, min_)\n",
    "    nrow, ncol = xx.shape  # 获取数据的行数和列数\n",
    "    \n",
    "    # 按照划分比例分别获取训练集、验证集和测试集\n",
    "    train_end = int(nrow * train_split)\n",
    "    val_end = int(nrow * (train_split + val_split))\n",
    "    \n",
    "    xx_train = xx[:train_end, :]  # 训练集数据\n",
    "    xx_val = xx[train_end:val_end, :]  # 验证集数据\n",
    "    xx_test = xx[val_end:, :]  # 测试集数据\n",
    "\n",
    "    # 生成训练集样本\n",
    "    train_x = np.zeros((xx_train.shape[0] - length + 1, length, ncol))\n",
    "    for i in range(train_x.shape[0]):\n",
    "        train_x[i, ...] = xx_train[i:i + length, :]\n",
    "\n",
    "    # 生成验证集样本\n",
    "    valid_x = np.zeros((xx_val.shape[0] - length + 1, length, ncol))\n",
    "    for i in range(valid_x.shape[0]):\n",
    "        valid_x[i, ...] = xx_val[i:i + length, :]\n",
    "\n",
    "    # 生成测试集样本\n",
    "    test_x = np.zeros((xx_test.shape[0] - length + 1, length, ncol))\n",
    "    for i in range(test_x.shape[0]):\n",
    "        test_x[i, ...] = xx_test[i:i + length, :]\n",
    "\n",
    "    # 构建数据字典\n",
    "    all_data = {\n",
    "        'train': {\n",
    "            'x': np.expand_dims(np.transpose(train_x, (0, 2, 1)), 2),  # 训练集输入数据\n",
    "            'target': np.expand_dims(np.transpose(train_x, (0, 2, 1)), 2),  # 训练集目标数据\n",
    "        },\n",
    "        'val': {\n",
    "            'x': np.expand_dims(np.transpose(valid_x, (0, 2, 1)), 2),  # 验证集输入数据\n",
    "            'target': np.expand_dims(np.transpose(valid_x, (0, 2, 1)), 2),  # 验证集目标数据\n",
    "        },\n",
    "        'test': {\n",
    "            'x': np.expand_dims(np.transpose(test_x, (0, 2, 1)), 2),  # 测试集输入数据\n",
    "            'target': np.expand_dims(np.transpose(test_x, (0, 2, 1)), 2),  # 测试集目标数据\n",
    "        },\n",
    "        'stats': {\n",
    "            '_mean': np.zeros((1, 1, 3, 1)),  # 初始化均值\n",
    "            '_std': np.zeros((1, 1, 3, 1)),  # 初始化标准差\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 如果没有提供文件名，就直接返回数据\n",
    "    if filename is None:\n",
    "        return max_, min_, all_data\n",
    "\n",
    "    # 将数据保存为.npz文件\n",
    "    np.savez_compressed(filename,\n",
    "                        train_x=all_data['train']['x'], train_target=all_data['train']['target'],\n",
    "                        val_x=all_data['val']['x'], val_target=all_data['val']['target'],\n",
    "                        test_x=all_data['test']['x'], test_target=all_data['test']['target'],\n",
    "                        mean=all_data['stats']['_mean'], std=all_data['stats']['_std'])\n",
    "\n",
    "    return max_, min_, all_data\n",
    "\n",
    "split = 0.8  # 训练集和验证集的划分比例，80%数据用于训练\n",
    "length = config.target_len  # 配置文件中指定的序列长度\n",
    "\n",
    "data = downsampling(swat_abnormal_np, config.downsampling_fre)\n",
    "max_, min_, all_data = swat_generate_data(copy.copy(data), train_split=0.7, val_split=0.2, length=50, filename=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_train(filename, DEVICE, batch_size, shuffle=True):\n",
    "    # 加载npz文件\n",
    "    file_data = np.load(filename)\n",
    "\n",
    "    # 加载训练数据和目标\n",
    "    train_x = file_data['train_x']  # 训练集输入\n",
    "    train_x = train_x[:, :, 0:1, :]  # (B, N, F, T)\n",
    "    train_target = file_data['train_target']  # 训练集目标\n",
    "\n",
    "    # 加载验证数据和目标\n",
    "    val_x = file_data['val_x']  # 验证集输入\n",
    "    val_x = val_x[:, :, 0:1, :]  # (B, N, F, T)\n",
    "    val_target = file_data['val_target']  # 验证集目标\n",
    "\n",
    "    # 加载测试数据和目标\n",
    "    test_x = file_data['test_x']  # 测试集输入\n",
    "    test_x = test_x[:, :, 0:1, :]  # (B, N, F, T)\n",
    "    test_target = file_data['test_target']  # 测试集目标\n",
    "\n",
    "    # 提取均值和标准差\n",
    "    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
    "    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
    "\n",
    "    # -------- 处理训练集标签 --------\n",
    "    train_label = train_target[:, :, -1]  # 提取最后一列作为标签\n",
    "    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)\n",
    "    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)\n",
    "    train_label_tensor = torch.from_numpy(train_label).type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor, train_label_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    # -------- 处理验证集标签 --------\n",
    "    val_label = val_target[:, :, -1]  # 提取最后一列作为标签\n",
    "    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)\n",
    "    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)\n",
    "    val_label_tensor = torch.from_numpy(val_label).type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor, val_label_tensor)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # -------- 处理测试集标签 --------\n",
    "    test_label = test_target[:, :, -1]  # 提取最后一列作为标签\n",
    "    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)\n",
    "    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor, test_label_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 打印数据维度信息\n",
    "    print('train:', train_x_tensor.size(), train_target_tensor.size(), train_label_tensor.size())\n",
    "    print('val:', val_x_tensor.size(), val_target_tensor.size(), val_label_tensor.size())\n",
    "    print('test:', test_x_tensor.size(), test_target_tensor.size(), test_label_tensor.size())\n",
    "\n",
    "\n",
    "    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: torch.Size([4470, 52, 1, 30]) torch.Size([4470, 52, 1, 30]) torch.Size([4470, 52, 30])\n",
      "val: torch.Size([1471, 52, 1, 30]) torch.Size([1471, 52, 1, 30]) torch.Size([1471, 52, 30])\n",
      "test: torch.Size([1471, 52, 1, 30]) torch.Size([1471, 52, 1, 30]) torch.Size([1471, 52, 30])\n",
      "训练集目标维度: torch.Size([4470, 52, 1, 30])\n",
      "验证集目标维度: torch.Size([1471, 52, 1, 30])\n",
      "测试集目标维度: torch.Size([1471, 52, 1, 30])\n",
      "均值维度: (1, 1, 1, 1)\n",
      "标准差维度: (1, 1, 1, 1)\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([128, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([128, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([128, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n",
      "输入数据 (batch_x) 维度: torch.Size([118, 52, 1, 30])\n",
      "目标数据 (batch_y) 维度: torch.Size([118, 52, 1, 30])\n",
      "标签 (batch_label) 维度: torch.Size([118, 52, 30])\n",
      "tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from config_files.SWAT_config import Config\n",
    "# 初始化配置对象，读取配置参数\n",
    "config = Config()\n",
    "\n",
    "# 从配置中获取参数\n",
    "device = config.device  # 设备\n",
    "batch_size = config.batch_size  # 批处理大小\n",
    "learning_rate = config.learning_rate  # 学习率\n",
    "epochs = config.epochs  # 训练周期数\n",
    "train_filename = config.train_filename  # 训练数据文件名\n",
    "\n",
    "# 文件路径和参数\n",
    "filename = \"data/SWAT/all_data_diffpool.npz\"\n",
    "shuffle = True\n",
    "\n",
    "# 调用 load_data_train 函数，获取加载的数据\n",
    "train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std = load_data_train(\n",
    "    filename=filename,\n",
    "    DEVICE=device,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle\n",
    ")\n",
    "\n",
    "# 打印数据维度信息\n",
    "print(f\"训练集目标维度: {train_target_tensor.size()}\")\n",
    "print(f\"验证集目标维度: {val_target_tensor.size()}\")\n",
    "print(f\"测试集目标维度: {test_target_tensor.size()}\")\n",
    "print(f\"均值维度: {mean.shape}\")\n",
    "print(f\"标准差维度: {std.shape}\")\n",
    "\n",
    "# 示例：遍历训练集的数据\n",
    "for batch_x, batch_y, batch_label in train_loader:\n",
    "    print(f\"输入数据 (batch_x) 维度: {batch_x.size()}\")\n",
    "    print(f\"目标数据 (batch_y) 维度: {batch_y.size()}\")\n",
    "    print(f\"标签 (batch_label) 维度: {batch_label.size()}\")\n",
    "    print(batch_label.unique())\n",
    "    # break  # 仅打印第一个batch的维度信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
